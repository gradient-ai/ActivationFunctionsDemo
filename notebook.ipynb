{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  article dependencies\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm as tqdm_regular\n",
    "import seaborn as sns\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def linear_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the identity\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = [x for x in values]\n",
    "  return activations\n",
    "\n",
    "\n",
    "# generating values from -3 to 3\n",
    "values = np.arange(-3, 4)\n",
    "\n",
    "#  activating generated values\n",
    "activations = linear_activation(values)\n",
    "#  activations are the same as their original values\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations)\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary step activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def binary_step_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the binary step\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  for value in values:\n",
    "    if value < 0:\n",
    "      activations.append(0)\n",
    "    else:\n",
    "      activations.append(1)\n",
    "\n",
    "  return activations\n",
    "\n",
    "\n",
    "# generating values from -3 to 3\n",
    "values = np.arange(-3, 4)\n",
    "\n",
    "#  activating generated values\n",
    "activations = binary_step_activation(values)\n",
    "#  activations are zero for values less than zero\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations, drawstyle='steps-post')\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sigmoid activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sigmoid_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the sigmoid\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  for value in values:\n",
    "    activation = 1/(1 + np.exp((-1*value)))\n",
    "    activations.append(activation)\n",
    "\n",
    "  activations = [round(x, 3) for x in activations]\n",
    "  return activations\n",
    "\n",
    "\n",
    "#  generating values from -5 to 5\n",
    "values = np.arange(-5, 6)\n",
    "\n",
    "#  activating generated values\n",
    "activations = sigmoid_activation(values)\n",
    "#  all activations are now constrained between 0 and 1\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations)\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tanh activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tanh_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the tanh\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  for value in values:\n",
    "    activation = (np.exp(value) - np.exp((-1*value))) / \\\n",
    "        (np.exp(value) + np.exp((-1*value)))\n",
    "    activations.append(activation)\n",
    "\n",
    "  activations = [round(x, 2) for x in activations]\n",
    "  return activations\n",
    "\n",
    "\n",
    "#  generating values from -5 to 5\n",
    "values = np.arange(-5, 6)\n",
    "\n",
    "#  activating generated values\n",
    "activations = tanh_activation(values)\n",
    "#  all activations are now constrained between -1 and 1\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations)\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLu activations example and plots\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def relu_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the relu\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  for value in values:\n",
    "    activation = max(0, value)\n",
    "    activations.append(activation)\n",
    "\n",
    "  return activations\n",
    "\n",
    "\n",
    "#  generating values from -5 to 5\n",
    "values = np.arange(-5, 6)\n",
    "\n",
    "#  activating generated values\n",
    "activations = relu_activation(values)\n",
    "#  all negative values are zeroed\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations)\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Leaky ReLu activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def leaky_relu_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the leaky\n",
    "  relu activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  for value in values:\n",
    "    activation = max(0.01*value, value)\n",
    "    activations.append(activation)\n",
    "\n",
    "  return activations\n",
    "\n",
    "\n",
    "#  generating values from -5 to 5\n",
    "values = np.arange(-5, 6)\n",
    "\n",
    "#  activating generated values\n",
    "activations = leaky_relu_activation(values)\n",
    "#  negative values are not zeroed\n",
    "print(activations)\n",
    "\n",
    "#  plotting activations\n",
    "sns.lineplot(x=values, y=activations)\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('activations')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax activations example and plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def softmax_activation(values):\n",
    "  \"\"\"\n",
    "  This function replicates the softmax\n",
    "  activation function\n",
    "  \"\"\"\n",
    "  activations = []\n",
    "\n",
    "  exponent_sum = sum([np.exp(x) for x in values])\n",
    "\n",
    "  for value in values:\n",
    "    activation = np.exp(value)/exponent_sum\n",
    "    activations.append(activation)\n",
    "\n",
    "  activations = [round(x, 3) for x in activations]\n",
    "\n",
    "  return activations\n",
    "\n",
    "\n",
    "#  generating values from -5 to 5\n",
    "values = np.arange(-5, 6)\n",
    "\n",
    "#  activating generated values using softmax\n",
    "softmax_activations = softmax_activation(values)\n",
    "#  values all sum up to 1\n",
    "print(softmax_activations)\n",
    "\n",
    "#  activating generated values using sigmoid\n",
    "sigmoid_activations = sigmoid_activation(values)\n",
    "sigmoid_activations\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}